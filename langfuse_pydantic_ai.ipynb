{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNNaDBe8p+jsJCsHAuRdiBo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/syakesaba/jupyter-notebooks/blob/main/langfuse_pydantic_ai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "UgljUOBpofpr"
      },
      "outputs": [],
      "source": [
        "!pip install -qq pydantic_ai[logfire] nest_asyncio\n",
        "import os\n",
        "import base64\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply() # Google Colab自体がasyncio配下で動いているのでネストさせる。\n",
        "import logfire\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY = userdata.get(\"GOOGLE_API_KEY\") # Secrets（🔑）からGOOGLE_API_KEYをNotebook access可能にする\n",
        "LANGFUSE_PUBLIC_KEY = userdata.get(\"LANGFUSE_PUBLIC_KEY\") # Secrets（🔑）からLANGFUSE_PUBLIC_KEYをNotebook access可能にする\n",
        "LANGFUSE_SECRET_KEY = userdata.get(\"LANGFUSE_SECRET_KEY\") # Secrets（🔑）からLANGFUSE_SECRET_KEYをNotebook access可能にする\n",
        "LANGFUSE_HOST = userdata.get(\"LANGFUSE_HOST\") # Secrets（🔑）からLANGFUSE_HOSTをNotebook access可能にする\n",
        "\n",
        "# GeminiModelに関する環境変数をGoogle Colabに作成\n",
        "os.environ[\"GEMINI_API_KEY\"] = GOOGLE_API_KEY\n",
        "\n",
        "# OTLP_EXPORTERに関する環境変数をGoogle Colabに作成\n",
        "# https://langfuse.com/docs/integrations/pydantic-ai\n",
        "LANGFUSE_AUTH = base64.b64encode(f\"{LANGFUSE_PUBLIC_KEY}:{LANGFUSE_SECRET_KEY}\".encode()).decode()\n",
        "os.environ[\"OTEL_EXPORTER_OTLP_ENDPOINT\"] = f\"{LANGFUSE_HOST}/api/public/otel\"\n",
        "os.environ[\"OTEL_EXPORTER_OTLP_HEADERS\"] = f\"Authorization=Basic {LANGFUSE_AUTH}\"\n",
        "\n",
        "# logfire cloudへの余計な送信を無効化\n",
        "import logfire\n",
        "_ = logfire.configure(\n",
        "    service_name='MyGoogleColab',\n",
        "    # Sending to Logfire is on by default regardless of the OTEL env vars.\n",
        "    send_to_logfire=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic_ai import Agent\n",
        "from pydantic_ai.models.gemini import GeminiModel\n",
        "from pydantic import BaseModel\n",
        "model = GeminiModel(\"gemini-2.0-flash\")\n",
        "agent = Agent(model=model, instrument=True)\n",
        "result = await agent.run(\"1+1=?\")\n",
        "print(result.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIvtZpOwo8RU",
        "outputId": "26e59c10-673a-4010-9c6a-34f931696a4e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14:45:30.155 agent run\n",
            "14:45:30.162   preparing model request params\n",
            "14:45:30.162   chat gemini-2.0-flash\n",
            "1 + 1 = 2\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from typing import Annotated, Optional\n",
        "from pydantic_ai import Agent, RunContext\n",
        "from pydantic_ai.models.gemini import GeminiModel\n",
        "from pydantic import BaseModel, StringConstraints\n",
        "from dataclasses import dataclass\n",
        "\n",
        "model = GeminiModel(\"gemini-2.0-flash\")\n",
        "\n",
        "@dataclass\n",
        "class JankenResult:\n",
        "    result: Annotated[str, StringConstraints(pattern=\"^(グー|チョキ|パー)$\")] | None\n",
        "\n",
        "@dataclass\n",
        "class JankenResults:\n",
        "    mario: JankenResult\n",
        "    luigi: JankenResult\n",
        "\n",
        "mario = Agent(\n",
        "    model=model, name=\"Mario\",\n",
        "    system_prompt=\"あなたはジャンケンをするAIエージェントです。\"\n",
        "                  \"'get_janken' toolを使用し、ジャンケンで「グー」、「チョキ」、「パー」のどれかをランダムに出します。\",\n",
        "    deps_type=None, result_type=JankenResult, instrument=True\n",
        ")\n",
        "luigi = Agent(\n",
        "    model=model, name=\"Luigi\",\n",
        "    system_prompt=\"あなたはジャンケンをするAIエージェントです。\"\n",
        "                  \"'get_janken' toolを使用し、ジャンケンで「グー」、「チョキ」、「パー」のどれかをランダムに出します。\",\n",
        "    deps_type=None, result_type=JankenResult, instrument=True\n",
        ")\n",
        "peach = Agent(\n",
        "    model=model, name=\"Peach\",\n",
        "    system_prompt=\"あなたはジャンケン勝負の結果を出力するAIエージェントです。\"\n",
        "                  \"'prompt_janken' toolを使用し、ジャンケン勝負の結果と勝敗を出力してください。\",\n",
        "    deps_type=JankenResults, result_type=str, instrument=True\n",
        ")\n",
        "\n",
        "yoshi = Agent(\n",
        "    model=model, name=\"Yoshi\",\n",
        "    system_prompt=\"あなたは親切なAIエージェントです。\"\n",
        "                  \"get_janken_results' toolを使用し結果を教えてください。\",\n",
        "    deps_type=None, result_type=str, instrument=True\n",
        ")\n",
        "\n",
        "@mario.tool\n",
        "def get_janken(ctx: RunContext[None]) -> str:\n",
        "    return random.choice([\"グー\", \"チョキ\", \"パー\"])\n",
        "\n",
        "@luigi.tool\n",
        "def get_janken(ctx: RunContext[None]) -> str:\n",
        "    return random.choice([\"グー\", \"チョキ\", \"パー\"])\n",
        "\n",
        "@peach.tool\n",
        "async def prompt_janken(ctx: RunContext[None]) -> str:\n",
        "    mario_response = await mario.run(\n",
        "        f'ジャンケン、',\n",
        "        usage=ctx.usage,\n",
        "    )\n",
        "    luigi_response = await luigi.run(\n",
        "        f'ジャンケン、',\n",
        "        usage=ctx.usage,\n",
        "    )\n",
        "    jankenResults = JankenResults(mario=mario_response.data, luigi=luigi_response.data)\n",
        "    print(jankenResults)\n",
        "    if jankenResults.mario.result == \"グー\" and jankenResults.luigi.result == \"グー\":\n",
        "        return \"双方グーで引き分けです。\"\n",
        "    elif jankenResults.mario.result == \"グー\" and jankenResults.luigi.result == \"チョキ\":\n",
        "        return \"Marioがグーで勝ちです。\"\n",
        "    elif jankenResults.mario.result == \"グー\" and jankenResults.luigi.result == \"パー\":\n",
        "        return \"Luigiがパーで勝ちです。\"\n",
        "    elif jankenResults.mario.result == \"チョキ\" and jankenResults.luigi.result == \"グー\":\n",
        "        return \"Luigiがグーで勝ちです。\"\n",
        "    elif jankenResults.mario.result == \"チョキ\" and jankenResults.luigi.result == \"チョキ\":\n",
        "        return \"双方チョキで引き分けです。\"\n",
        "    elif jankenResults.mario.result == \"チョキ\" and jankenResults.luigi.result == \"パー\":\n",
        "        return \"Marioがチョキで勝ちです。\"\n",
        "    elif jankenResults.mario.result == \"パー\" and jankenResults.luigi.result == \"グー\":\n",
        "        return \"Marioがパーで勝ちです。\"\n",
        "    elif jankenResults.mario.result == \"パー\" and jankenResults.luigi.result == \"チョキ\":\n",
        "        return \"Luigiがチョキで勝ちです。\"\n",
        "    elif jankenResults.mario.result == \"パー\" and jankenResults.luigi.result == \"パー\":\n",
        "        return \"双方パーで引き分けです。\"\n",
        "    else:\n",
        "        return \"不明な結果です。\"\n",
        "\n",
        "@yoshi.tool\n",
        "async def get_janken_results(ctx: RunContext[None]) -> str:\n",
        "    response = await peach.run(\"ジャンケン勝負の結果と勝敗を出力してください\", usage=ctx.usage)\n",
        "    return response.data\n",
        "\n",
        "result = await yoshi.run(\"どちらがどの手を出したかと、勝敗を教えて下さい。\", deps=None, result_type=str)\n",
        "print(result.data) # マリオがチョキを出して勝ちました。\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCYTI1ILxZg1",
        "outputId": "5ff39539-6567-4d90-926a-15e489a53735"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14:51:56.989 Yoshi run\n",
            "14:51:56.990   preparing model request params\n",
            "14:51:56.991   chat gemini-2.0-flash\n",
            "14:51:57.898   running tools: get_janken_results\n",
            "14:51:57.899     Peach run\n",
            "14:51:57.900       preparing model request params\n",
            "14:51:57.900       chat gemini-2.0-flash\n",
            "14:51:58.369       running tools: prompt_janken\n",
            "14:51:58.371         Mario run\n",
            "14:51:58.371           preparing model request params\n",
            "14:51:58.372           chat gemini-2.0-flash\n",
            "14:51:58.866           running tools: get_janken\n",
            "14:51:58.868           preparing model request params\n",
            "14:51:58.869           chat gemini-2.0-flash\n",
            "14:51:59.395         Luigi run\n",
            "14:51:59.395           preparing model request params\n",
            "14:51:59.396           chat gemini-2.0-flash\n",
            "14:52:00.155           running tools: get_janken\n",
            "14:52:00.157           preparing model request params\n",
            "14:52:00.157           chat gemini-2.0-flash\n",
            "JankenResults(mario=JankenResult(result='チョキ'), luigi=JankenResult(result='パー'))\n",
            "14:52:00.627       preparing model request params\n",
            "14:52:00.628       chat gemini-2.0-flash\n",
            "14:52:01.637   preparing model request params\n",
            "14:52:01.637   chat gemini-2.0-flash\n",
            "マリオがチョキを出して勝ちました。\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZwU_tmLJyS5M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}