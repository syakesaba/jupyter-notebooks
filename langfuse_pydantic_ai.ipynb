{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNNaDBe8p+jsJCsHAuRdiBo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/syakesaba/jupyter-notebooks/blob/main/langfuse_pydantic_ai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "UgljUOBpofpr"
      },
      "outputs": [],
      "source": [
        "!pip install -qq pydantic_ai[logfire] nest_asyncio\n",
        "import os\n",
        "import base64\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply() # Google Colabè‡ªä½“ãŒasyncioé…ä¸‹ã§å‹•ã„ã¦ã„ã‚‹ã®ã§ãƒã‚¹ãƒˆã•ã›ã‚‹ã€‚\n",
        "import logfire\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY = userdata.get(\"GOOGLE_API_KEY\") # Secretsï¼ˆğŸ”‘ï¼‰ã‹ã‚‰GOOGLE_API_KEYã‚’Notebook accesså¯èƒ½ã«ã™ã‚‹\n",
        "LANGFUSE_PUBLIC_KEY = userdata.get(\"LANGFUSE_PUBLIC_KEY\") # Secretsï¼ˆğŸ”‘ï¼‰ã‹ã‚‰LANGFUSE_PUBLIC_KEYã‚’Notebook accesså¯èƒ½ã«ã™ã‚‹\n",
        "LANGFUSE_SECRET_KEY = userdata.get(\"LANGFUSE_SECRET_KEY\") # Secretsï¼ˆğŸ”‘ï¼‰ã‹ã‚‰LANGFUSE_SECRET_KEYã‚’Notebook accesså¯èƒ½ã«ã™ã‚‹\n",
        "LANGFUSE_HOST = userdata.get(\"LANGFUSE_HOST\") # Secretsï¼ˆğŸ”‘ï¼‰ã‹ã‚‰LANGFUSE_HOSTã‚’Notebook accesså¯èƒ½ã«ã™ã‚‹\n",
        "\n",
        "# GeminiModelã«é–¢ã™ã‚‹ç’°å¢ƒå¤‰æ•°ã‚’Google Colabã«ä½œæˆ\n",
        "os.environ[\"GEMINI_API_KEY\"] = GOOGLE_API_KEY\n",
        "\n",
        "# OTLP_EXPORTERã«é–¢ã™ã‚‹ç’°å¢ƒå¤‰æ•°ã‚’Google Colabã«ä½œæˆ\n",
        "# https://langfuse.com/docs/integrations/pydantic-ai\n",
        "LANGFUSE_AUTH = base64.b64encode(f\"{LANGFUSE_PUBLIC_KEY}:{LANGFUSE_SECRET_KEY}\".encode()).decode()\n",
        "os.environ[\"OTEL_EXPORTER_OTLP_ENDPOINT\"] = f\"{LANGFUSE_HOST}/api/public/otel\"\n",
        "os.environ[\"OTEL_EXPORTER_OTLP_HEADERS\"] = f\"Authorization=Basic {LANGFUSE_AUTH}\"\n",
        "\n",
        "# logfire cloudã¸ã®ä½™è¨ˆãªé€ä¿¡ã‚’ç„¡åŠ¹åŒ–\n",
        "import logfire\n",
        "_ = logfire.configure(\n",
        "    service_name='MyGoogleColab',\n",
        "    # Sending to Logfire is on by default regardless of the OTEL env vars.\n",
        "    send_to_logfire=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic_ai import Agent\n",
        "from pydantic_ai.models.gemini import GeminiModel\n",
        "from pydantic import BaseModel\n",
        "model = GeminiModel(\"gemini-2.0-flash\")\n",
        "agent = Agent(model=model, instrument=True)\n",
        "result = await agent.run(\"1+1=?\")\n",
        "print(result.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIvtZpOwo8RU",
        "outputId": "26e59c10-673a-4010-9c6a-34f931696a4e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14:45:30.155 agent run\n",
            "14:45:30.162   preparing model request params\n",
            "14:45:30.162   chat gemini-2.0-flash\n",
            "1 + 1 = 2\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from typing import Annotated, Optional\n",
        "from pydantic_ai import Agent, RunContext\n",
        "from pydantic_ai.models.gemini import GeminiModel\n",
        "from pydantic import BaseModel, StringConstraints\n",
        "from dataclasses import dataclass\n",
        "\n",
        "model = GeminiModel(\"gemini-2.0-flash\")\n",
        "\n",
        "@dataclass\n",
        "class JankenResult:\n",
        "    result: Annotated[str, StringConstraints(pattern=\"^(ã‚°ãƒ¼|ãƒãƒ§ã‚­|ãƒ‘ãƒ¼)$\")] | None\n",
        "\n",
        "@dataclass\n",
        "class JankenResults:\n",
        "    mario: JankenResult\n",
        "    luigi: JankenResult\n",
        "\n",
        "mario = Agent(\n",
        "    model=model, name=\"Mario\",\n",
        "    system_prompt=\"ã‚ãªãŸã¯ã‚¸ãƒ£ãƒ³ã‚±ãƒ³ã‚’ã™ã‚‹AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚\"\n",
        "                  \"'get_janken' toolã‚’ä½¿ç”¨ã—ã€ã‚¸ãƒ£ãƒ³ã‚±ãƒ³ã§ã€Œã‚°ãƒ¼ã€ã€ã€Œãƒãƒ§ã‚­ã€ã€ã€Œãƒ‘ãƒ¼ã€ã®ã©ã‚Œã‹ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«å‡ºã—ã¾ã™ã€‚\",\n",
        "    deps_type=None, result_type=JankenResult, instrument=True\n",
        ")\n",
        "luigi = Agent(\n",
        "    model=model, name=\"Luigi\",\n",
        "    system_prompt=\"ã‚ãªãŸã¯ã‚¸ãƒ£ãƒ³ã‚±ãƒ³ã‚’ã™ã‚‹AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚\"\n",
        "                  \"'get_janken' toolã‚’ä½¿ç”¨ã—ã€ã‚¸ãƒ£ãƒ³ã‚±ãƒ³ã§ã€Œã‚°ãƒ¼ã€ã€ã€Œãƒãƒ§ã‚­ã€ã€ã€Œãƒ‘ãƒ¼ã€ã®ã©ã‚Œã‹ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«å‡ºã—ã¾ã™ã€‚\",\n",
        "    deps_type=None, result_type=JankenResult, instrument=True\n",
        ")\n",
        "peach = Agent(\n",
        "    model=model, name=\"Peach\",\n",
        "    system_prompt=\"ã‚ãªãŸã¯ã‚¸ãƒ£ãƒ³ã‚±ãƒ³å‹è² ã®çµæœã‚’å‡ºåŠ›ã™ã‚‹AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚\"\n",
        "                  \"'prompt_janken' toolã‚’ä½¿ç”¨ã—ã€ã‚¸ãƒ£ãƒ³ã‚±ãƒ³å‹è² ã®çµæœã¨å‹æ•—ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚\",\n",
        "    deps_type=JankenResults, result_type=str, instrument=True\n",
        ")\n",
        "\n",
        "yoshi = Agent(\n",
        "    model=model, name=\"Yoshi\",\n",
        "    system_prompt=\"ã‚ãªãŸã¯è¦ªåˆ‡ãªAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚\"\n",
        "                  \"get_janken_results' toolã‚’ä½¿ç”¨ã—çµæœã‚’æ•™ãˆã¦ãã ã•ã„ã€‚\",\n",
        "    deps_type=None, result_type=str, instrument=True\n",
        ")\n",
        "\n",
        "@mario.tool\n",
        "def get_janken(ctx: RunContext[None]) -> str:\n",
        "    return random.choice([\"ã‚°ãƒ¼\", \"ãƒãƒ§ã‚­\", \"ãƒ‘ãƒ¼\"])\n",
        "\n",
        "@luigi.tool\n",
        "def get_janken(ctx: RunContext[None]) -> str:\n",
        "    return random.choice([\"ã‚°ãƒ¼\", \"ãƒãƒ§ã‚­\", \"ãƒ‘ãƒ¼\"])\n",
        "\n",
        "@peach.tool\n",
        "async def prompt_janken(ctx: RunContext[None]) -> str:\n",
        "    mario_response = await mario.run(\n",
        "        f'ã‚¸ãƒ£ãƒ³ã‚±ãƒ³ã€',\n",
        "        usage=ctx.usage,\n",
        "    )\n",
        "    luigi_response = await luigi.run(\n",
        "        f'ã‚¸ãƒ£ãƒ³ã‚±ãƒ³ã€',\n",
        "        usage=ctx.usage,\n",
        "    )\n",
        "    jankenResults = JankenResults(mario=mario_response.data, luigi=luigi_response.data)\n",
        "    print(jankenResults)\n",
        "    if jankenResults.mario.result == \"ã‚°ãƒ¼\" and jankenResults.luigi.result == \"ã‚°ãƒ¼\":\n",
        "        return \"åŒæ–¹ã‚°ãƒ¼ã§å¼•ãåˆ†ã‘ã§ã™ã€‚\"\n",
        "    elif jankenResults.mario.result == \"ã‚°ãƒ¼\" and jankenResults.luigi.result == \"ãƒãƒ§ã‚­\":\n",
        "        return \"MarioãŒã‚°ãƒ¼ã§å‹ã¡ã§ã™ã€‚\"\n",
        "    elif jankenResults.mario.result == \"ã‚°ãƒ¼\" and jankenResults.luigi.result == \"ãƒ‘ãƒ¼\":\n",
        "        return \"LuigiãŒãƒ‘ãƒ¼ã§å‹ã¡ã§ã™ã€‚\"\n",
        "    elif jankenResults.mario.result == \"ãƒãƒ§ã‚­\" and jankenResults.luigi.result == \"ã‚°ãƒ¼\":\n",
        "        return \"LuigiãŒã‚°ãƒ¼ã§å‹ã¡ã§ã™ã€‚\"\n",
        "    elif jankenResults.mario.result == \"ãƒãƒ§ã‚­\" and jankenResults.luigi.result == \"ãƒãƒ§ã‚­\":\n",
        "        return \"åŒæ–¹ãƒãƒ§ã‚­ã§å¼•ãåˆ†ã‘ã§ã™ã€‚\"\n",
        "    elif jankenResults.mario.result == \"ãƒãƒ§ã‚­\" and jankenResults.luigi.result == \"ãƒ‘ãƒ¼\":\n",
        "        return \"MarioãŒãƒãƒ§ã‚­ã§å‹ã¡ã§ã™ã€‚\"\n",
        "    elif jankenResults.mario.result == \"ãƒ‘ãƒ¼\" and jankenResults.luigi.result == \"ã‚°ãƒ¼\":\n",
        "        return \"MarioãŒãƒ‘ãƒ¼ã§å‹ã¡ã§ã™ã€‚\"\n",
        "    elif jankenResults.mario.result == \"ãƒ‘ãƒ¼\" and jankenResults.luigi.result == \"ãƒãƒ§ã‚­\":\n",
        "        return \"LuigiãŒãƒãƒ§ã‚­ã§å‹ã¡ã§ã™ã€‚\"\n",
        "    elif jankenResults.mario.result == \"ãƒ‘ãƒ¼\" and jankenResults.luigi.result == \"ãƒ‘ãƒ¼\":\n",
        "        return \"åŒæ–¹ãƒ‘ãƒ¼ã§å¼•ãåˆ†ã‘ã§ã™ã€‚\"\n",
        "    else:\n",
        "        return \"ä¸æ˜ãªçµæœã§ã™ã€‚\"\n",
        "\n",
        "@yoshi.tool\n",
        "async def get_janken_results(ctx: RunContext[None]) -> str:\n",
        "    response = await peach.run(\"ã‚¸ãƒ£ãƒ³ã‚±ãƒ³å‹è² ã®çµæœã¨å‹æ•—ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„\", usage=ctx.usage)\n",
        "    return response.data\n",
        "\n",
        "result = await yoshi.run(\"ã©ã¡ã‚‰ãŒã©ã®æ‰‹ã‚’å‡ºã—ãŸã‹ã¨ã€å‹æ•—ã‚’æ•™ãˆã¦ä¸‹ã•ã„ã€‚\", deps=None, result_type=str)\n",
        "print(result.data) # ãƒãƒªã‚ªãŒãƒãƒ§ã‚­ã‚’å‡ºã—ã¦å‹ã¡ã¾ã—ãŸã€‚\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCYTI1ILxZg1",
        "outputId": "5ff39539-6567-4d90-926a-15e489a53735"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14:51:56.989 Yoshi run\n",
            "14:51:56.990   preparing model request params\n",
            "14:51:56.991   chat gemini-2.0-flash\n",
            "14:51:57.898   running tools: get_janken_results\n",
            "14:51:57.899     Peach run\n",
            "14:51:57.900       preparing model request params\n",
            "14:51:57.900       chat gemini-2.0-flash\n",
            "14:51:58.369       running tools: prompt_janken\n",
            "14:51:58.371         Mario run\n",
            "14:51:58.371           preparing model request params\n",
            "14:51:58.372           chat gemini-2.0-flash\n",
            "14:51:58.866           running tools: get_janken\n",
            "14:51:58.868           preparing model request params\n",
            "14:51:58.869           chat gemini-2.0-flash\n",
            "14:51:59.395         Luigi run\n",
            "14:51:59.395           preparing model request params\n",
            "14:51:59.396           chat gemini-2.0-flash\n",
            "14:52:00.155           running tools: get_janken\n",
            "14:52:00.157           preparing model request params\n",
            "14:52:00.157           chat gemini-2.0-flash\n",
            "JankenResults(mario=JankenResult(result='ãƒãƒ§ã‚­'), luigi=JankenResult(result='ãƒ‘ãƒ¼'))\n",
            "14:52:00.627       preparing model request params\n",
            "14:52:00.628       chat gemini-2.0-flash\n",
            "14:52:01.637   preparing model request params\n",
            "14:52:01.637   chat gemini-2.0-flash\n",
            "ãƒãƒªã‚ªãŒãƒãƒ§ã‚­ã‚’å‡ºã—ã¦å‹ã¡ã¾ã—ãŸã€‚\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZwU_tmLJyS5M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}