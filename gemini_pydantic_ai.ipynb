{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/syakesaba/jupyter-notebooks/blob/main/gemini_pydantic_ai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# åˆå›å®Ÿè¡Œå¿…è¦"
      ],
      "metadata": {
        "id": "QPedvJQbzqvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qq pydantic_ai nest_asyncio\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply() # Google Colabè‡ªä½“ãŒasyncioé…ä¸‹ã§å‹•ã„ã¦ã„ã‚‹ã®ã§ãƒã‚¹ãƒˆã•ã›ã‚‹ã€‚\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY=userdata.get(\"GOOGLE_API_KEY\") # Secretsï¼ˆğŸ”‘ï¼‰ã‹ã‚‰GOOGLE_API_KEYã‚’Notebook accesså¯èƒ½ã«ã™ã‚‹\n",
        "import os\n",
        "os.environ[\"GEMINI_API_KEY\"] = GOOGLE_API_KEY"
      ],
      "metadata": {
        "id": "CgPmAsSvPZYS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# é€šå¸¸ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ\n"
      ],
      "metadata": {
        "id": "ZwWD7D-65zLK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic_ai import Agent\n",
        "from pydantic_ai.models.gemini import GeminiModel\n",
        "from pydantic import BaseModel\n",
        "\n",
        "model = GeminiModel(\"gemini-2.0-flash\")\n",
        "\n",
        "# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯æ–‡å­—åˆ—ãŒè¿”ã£ã¦ãã‚‹ä¸Šã«ã€æœ€å¾Œã«æ”¹è¡ŒãŒå…¥ã£ã¦ãã‚‹\n",
        "agent = Agent(model=model)\n",
        "result = await agent.run(\"1+1=?\")\n",
        "print(result.data)\n",
        "\n",
        "# === å¿œç­”ã®å‹ã®å¤‰æ›´ ===\n",
        "\n",
        "# å¼·åˆ¶çš„ã«æ•°å­—ã§è¿”ã•ã›ã‚‹ã“ã¨ã‚‚å¯èƒ½\n",
        "agent = Agent(model=model, result_type=int)\n",
        "result = await agent.run(\"1+1=?\")\n",
        "print(result.data) # 2 ãŒæ•°å­—ã§è¿”ã£ã¦ãã‚‹\n",
        "agent = Agent(model=model, result_type=int)\n",
        "result = await agent.run(\"æ°´æ›œæ—¥ã®æ¬¡ã¯ä½•æ›œæ—¥ï¼Ÿ\")\n",
        "print(result.data) # ã“ã‚Œã‚‚ãªã‚“ã¨ã‹ã—ã¦æ•°å­—ã§è¿”ãã†ã¨ã—ã¦ãã‚‹ã€‚æ—¥æ›œæ—¥ã¯0ã€æœˆæ›œæ—¥ã¯1ã€ã¨ã„ã£ãŸå¡©æ¢…ã§ã‚ã‚‹ã€‚\n",
        "\n",
        "# runå®Ÿè¡Œæ™‚ã«ã•ã‚‰ã«å¼·åˆ¶çš„ã«æ–‡å­—åˆ—ã§è¿”ã•ã›ã‚‹ã“ã¨ã‚‚å¯èƒ½\n",
        "agent = Agent(model=model, result_type=int)\n",
        "result = await agent.run(\"åœŸæ›œæ—¥ã®æ¬¡ã¯ä½•æ›œæ—¥ï¼Ÿ\", result_type=str)\n",
        "print(result.data) # æ–‡å­—åˆ—ã§è¿”ã•ã‚Œã‚‹ã€‚æœ€å¾Œã«æ”¹è¡ŒãŒå…¥ã£ã¦ãã‚‹\n",
        "\n",
        "# æ§‹é€ ä½“ã‚‚å¯èƒ½ã€‚ã“ã®å ´åˆã€å¤‰æ•°åãŒæ„å‘³ã‚’æŒã¤ã®ã§æ³¨æ„ãŒå¿…è¦ã€‚\n",
        "class Answer(BaseModel):\n",
        "    æ›œæ—¥: str\n",
        "    æ—¥ä»˜: int\n",
        "agent = Agent(model=model, result_type=Answer)\n",
        "result = await agent.run(\"åœŸæ›œæ—¥ãŒ12æ—¥ã ã¨ã—ã¦ã€ãã®4æ—¥å¾Œã¯ä½•æ›œæ—¥ã®ä½•æ—¥ï¼Ÿ\")\n",
        "print(result.data.æ›œæ—¥, result.data.æ—¥ä»˜)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzDUxVEBQKoP",
        "outputId": "5aeca410-0855-4193-ed67-cd3d239f7978"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 + 1 = 2\n",
            "\n",
            "2\n",
            "4\n",
            "åœŸæ›œæ—¥ã®æ¬¡ã¯æ—¥æ›œæ—¥ã§ã™ã€‚\n",
            "\n",
            "æ°´æ›œæ—¥ 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic_ai import Agent, ModelRetry\n",
        "from pydantic_ai.models.gemini import GeminiModel\n",
        "\n",
        "from pydantic import BaseModel, StringConstraints\n",
        "from typing import Annotated\n",
        "\n",
        "model = GeminiModel(\"gemini-2.0-flash\")\n",
        "\n",
        "# === å¿œç­”ã®å‹ã®å¤‰æ›´ (åˆ¶é™ä»˜ãå¿œç­”) ===\n",
        "\n",
        "class Answer(BaseModel):\n",
        "    æ›œæ—¥: Annotated[str, StringConstraints(max_length=2)] # æ›œæ—¥ã‚’2æ–‡å­—ä»¥å†…ã§è¡¨ç¾ã™ã‚‹ã‚ˆã†ã«åˆ¶é™\n",
        "    æ—¥ä»˜: int\n",
        "\n",
        "agent = Agent(model=model, result_type=Answer)\n",
        "result = await agent.run(\"åœŸæ›œæ—¥ãŒ12æ—¥ã ã¨ã—ã¦ã€ãã®4æ—¥å¾Œã¯ä½•æ›œæ—¥ã®ä½•æ—¥ï¼Ÿ\")\n",
        "print(result.data.æ›œæ—¥, result.data.æ—¥ä»˜)\n",
        "\n",
        "class Answer(BaseModel):\n",
        "    æ›œæ—¥: Annotated[str, StringConstraints(pattern=\"^.æ›œæ—¥$\")] # \"æ°´æ›œæ—¥\" ã¨ã„ã†è¡¨ç¾ã«åˆ¶é™\n",
        "    æ—¥ä»˜: int\n",
        "\n",
        "agent = Agent(model=model, result_type=Answer)\n",
        "result = await agent.run(\"åœŸæ›œæ—¥ãŒ12æ—¥ã ã¨ã—ã¦ã€ãã®4æ—¥å¾Œã¯ä½•æ›œæ—¥ã®ä½•æ—¥ï¼Ÿ\")\n",
        "print(result.data.æ›œæ—¥, result.data.æ—¥ä»˜)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4lZkKwO6jtr",
        "outputId": "d96d37b9-c84c-4c16-818b-4a1af8bbac8a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "æ°´ 16\n",
            "æ°´æ›œæ—¥ 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"
      ],
      "metadata": {
        "id": "aVTSNqpYzPcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic_ai import Agent, RunContext\n",
        "from pydantic_ai.models.gemini import GeminiModel\n",
        "\n",
        "model = GeminiModel(\"gemini-2.0-flash\")\n",
        "\n",
        "# ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ã‚’ä½¿ã„ã€å‹•çš„ã«ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä»˜ä¸ã™ã‚‹å ´åˆ\n",
        "agent = Agent(model=model)\n",
        "@agent.system_prompt\n",
        "async def å…¥ã‚ŒçŸ¥æµ(ctx: RunContext[None]) -> str:\n",
        "    return \"ã‚ãªãŸã¯ã‚«ãƒ©ã‚¹ã®å°‚é–€å®¶ã§ã™ã€‚\"\n",
        "result = await agent.run(\"å¤šãã®ã‚«ãƒ©ã‚¹ã¯é»’ã„ã§ã™ã‹ï¼Ÿ\")\n",
        "print(result.data)\n",
        "\n",
        "# é™çš„ã«ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä»˜ä¸ã™ã‚‹å ´åˆ\n",
        "agent = Agent(model=model, system_prompt=\"ã‚ãªãŸã¯é€†ã®ã“ã¨ã‚’ä¼ãˆã‚‹AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚\")\n",
        "result = await agent.run(\"å¤šãã®ã‚«ãƒ©ã‚¹ã¯é»’ã„ã§ã™ã‹ï¼Ÿ\")\n",
        "print(result.data)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cL_NAQCxWW3f",
        "outputId": "4f993dea-4046-49f4-e6ed-c09f77142601"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ã¯ã„ã€å¤šãã®ã‚«ãƒ©ã‚¹ã¯é»’ã„ã§ã™ã€‚\n",
            "\n",
            "ãŸã ã—ã€ã€Œã‚«ãƒ©ã‚¹ã€ã¨å‘¼ã°ã‚Œã‚‹é³¥ã¯ä¸–ç•Œä¸­ã«æ§˜ã€…ãªç¨®é¡ãŒãŠã‚Šã€ãã®å…¨ã¦ãŒé»’ã„ã‚ã‘ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚\n",
            "\n",
            "*   **ãƒã‚·ãƒ–ãƒˆã‚¬ãƒ©ã‚¹ã€ãƒã‚·ãƒœã‚½ã‚¬ãƒ©ã‚¹**: æ—¥æœ¬ã§ã‚ˆãè¦‹ã‚‰ã‚Œã‚‹ã‚«ãƒ©ã‚¹ã§ã€å…¨èº«ãŒé»’ã„ç¾½æ¯›ã«è¦†ã‚ã‚Œã¦ã„ã¾ã™ã€‚\n",
            "*   **ãƒŸãƒ¤ãƒã‚¬ãƒ©ã‚¹**: ã“ã¡ã‚‰ã‚‚æ—¥æœ¬ã§è¦‹ã‚‰ã‚Œã¾ã™ãŒã€æˆé³¥ã«ãªã‚‹ã¨å˜´ã®æ ¹å…ƒãŒç™½ã£ã½ããªã‚Šã¾ã™ã€‚\n",
            "*   **ãƒ¯ã‚¿ãƒªã‚¬ãƒ©ã‚¹**: ä¸–ç•Œæœ€å¤§ç´šã®ã‚«ãƒ©ã‚¹ã§ã€å…¨èº«ãŒé»’ãã€é‡‘å±å…‰æ²¢ãŒã‚ã‚Šã¾ã™ã€‚\n",
            "*   **ãƒ‹ãƒ¥ã‚¦ã‚®ãƒ‹ã‚¢ã‚¬ãƒ©ã‚¹**: å…¨èº«ãŒé»’ã„ã§ã™ãŒã€ç›®ã®å‘¨ã‚Šã®çš®è†šãŒé’è‰²ã‚’ã—ã¦ã„ã¾ã™ã€‚\n",
            "*   **ã‚«ã‚µã‚µã‚®**: ç™½ã¨é»’ã®ãƒ„ãƒ¼ãƒˆãƒ³ã‚«ãƒ©ãƒ¼ã®ã‚«ãƒ©ã‚¹ã§ã€ãƒ¦ãƒ¼ãƒ©ã‚·ã‚¢å¤§é™¸ã«åºƒãåˆ†å¸ƒã—ã¦ã„ã¾ã™ã€‚\n",
            "*   **ã‚¢ã‚ªã‚«ã‚±ã‚¹**: é’ã„ç¾½æ¯›ã‚’æŒã¤ç¾ã—ã„ã‚«ãƒ©ã‚¹ã§ã€åŒ—ç±³ã«ç”Ÿæ¯ã—ã¦ã„ã¾ã™ã€‚\n",
            "\n",
            "ã“ã®ã‚ˆã†ã«ã€ã‚«ãƒ©ã‚¹ã®ç¨®é¡ã«ã‚ˆã£ã¦ä½“ã®è‰²ã¯æ§˜ã€…ã§ã™ã€‚ã—ã‹ã—ã€ä¸€èˆ¬çš„ã«ã€Œã‚«ãƒ©ã‚¹ã€ã¨ã—ã¦ã‚¤ãƒ¡ãƒ¼ã‚¸ã•ã‚Œã‚‹ã®ã¯ã€å…¨èº«ãŒé»’ã„ãƒã‚·ãƒ–ãƒˆã‚¬ãƒ©ã‚¹ã‚„ãƒã‚·ãƒœã‚½ã‚¬ãƒ©ã‚¹ã§ã‚ã‚‹ã“ã¨ãŒå¤šã„ãŸã‚ã€ã€Œå¤šãã®ã‚«ãƒ©ã‚¹ã¯é»’ã„ã€ã¨è¨€ãˆã¾ã™ã€‚\n",
            "ã„ã„ãˆã€ã‚«ãƒ©ã‚¹ã¯é»’ããªã„ã‚‚ã®ã¯ãŸãã•ã‚“ã„ã¾ã™ã€‚\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deps"
      ],
      "metadata": {
        "id": "5DFhZgypzScR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel\n",
        "from pydantic_ai import Agent, RunContext\n",
        "from pydantic_ai.models.gemini import GeminiModel\n",
        "\n",
        "model = GeminiModel(\"gemini-2.0-flash\")\n",
        "\n",
        "class Species(BaseModel):\n",
        "    åå‰: str\n",
        "    è‰²: str\n",
        "\n",
        "class Answer(BaseModel):\n",
        "    å›ç­”: bool\n",
        "    è£œè¶³äº‹é …: str\n",
        "\n",
        "agent = Agent(model=model, deps_type=Species, result_type=Answer)\n",
        "@agent.system_prompt\n",
        "async def å…¥ã‚ŒçŸ¥æµ(ctx: RunContext[Species]) -> str:\n",
        "    return f\"ã‚ãªãŸã¯{ctx.deps.åå‰}ã®å°‚é–€å®¶ã§ã™ã€‚\" # å¤‰æ•°åŒ–ã™ã‚‹ã“ã¨ã§ã€ã“ã®é–¢æ•°ã®å˜ä½“ãƒ†ã‚¹ãƒˆãŒã—ã‚„ã™ããªã‚‹ã€‚\n",
        "\n",
        "species = Species(åå‰=\"ã‚«ãƒ©ã‚¹\", è‰²=\"é»’ã„\")\n",
        "result = await agent.run(f\"å¤šãã®{species.åå‰}ã¯{species.è‰²}ã§ã™ã‹ï¼Ÿ\", deps=species) #\n",
        "print(result.data.å›ç­”)\n",
        "print(result.data.è£œè¶³äº‹é …)\n",
        "\n",
        "species = Species(åå‰=\"ã‚µã‚¤ã‚³ãƒ­\", è‰²=\"ç™½ã„\") # å¤‰æ•°åŒ–ã™ã‚‹ã“ã¨ã§ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å†åˆ©ç”¨ã‚‚ã—ã‚„ã™ããªã‚‹ã€‚\n",
        "result = await agent.run(f\"å¤šãã®{species.åå‰}ã¯{species.è‰²}ã§ã™ã‹ï¼Ÿ\", deps=species) #\n",
        "print(result.data.å›ç­”)\n",
        "print(result.data.è£œè¶³äº‹é …)"
      ],
      "metadata": {
        "id": "DjwwXd2fxc8M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d121b474-c6bf-46a1-9e7e-aebb083ec438"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "ã¯ã„ã€ã»ã¨ã‚“ã©ã®ã‚«ãƒ©ã‚¹ã¯é»’ã„ã§ã™ã€‚\n",
            "True\n",
            "å¤šãã®ã‚µã‚¤ã‚³ãƒ­ã¯ç™½ã„ã§ã™ã€‚\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tool"
      ],
      "metadata": {
        "id": "Pq1M9PjczU8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import zoneinfo\n",
        "from typing import Annotated\n",
        "from pydantic_ai import Agent, RunContext\n",
        "from pydantic_ai.models.gemini import GeminiModel\n",
        "from pydantic import BaseModel, StringConstraints\n",
        "\n",
        "model = GeminiModel(\"gemini-2.0-flash\")\n",
        "\n",
        "agent = Agent(model=model)\n",
        "@agent.tool_plain\n",
        "def get_today_date() -> str:\n",
        "    \"\"\"get today date as format \"%04Y-%02m-%02d\" in UTC\"\"\"\n",
        "    now = datetime.datetime.now(tz=datetime.timezone.utc)\n",
        "    return now.strftime(\"%04Y-%02m-%02d\")\n",
        "\n",
        "result = await agent.run(\"ä»Šæ—¥ã¯UTCã§ä½•æ—¥ï¼Ÿ\")\n",
        "print(result.data)\n",
        "\n",
        "# === toolã¨depsã®çµ„ã¿åˆã‚ã› ===\n",
        "\n",
        "class Timezone(BaseModel):\n",
        "    tzname: Annotated[str, StringConstraints(pattern=\"|\".join(zoneinfo.available_timezones()))]\n",
        "\n",
        "agent = Agent(model=model, deps_type=Timezone)\n",
        "\n",
        "@agent.tool\n",
        "def get_now_time(ctx: RunContext[Timezone]) -> str:\n",
        "    \"\"\"get now time as format \"%02H-%02M-%02S\" \"\"\"\n",
        "    now = datetime.datetime.now(tz=zoneinfo.ZoneInfo(ctx.deps.tzname))\n",
        "    return now.strftime(\"%02H-%02M-%02S\")\n",
        "\n",
        "tz = Timezone(tzname=\"Asia/Tokyo\")\n",
        "result = await agent.run(\"ä»Šä½•æ™‚ã§ã™ã‹ï¼Ÿ\", deps=tz)\n",
        "print(result.data) # JSTã§å¸°ã£ã¦æ¥ã‚‹\n",
        "\n",
        "tz = Timezone(tzname=\"UTC\")\n",
        "result = await agent.run(\"ä»Šä½•æ™‚ã§ã™ã‹ï¼Ÿ\", deps=tz)\n",
        "print(result.data) # UTCã§å¸°ã£ã¦æ¥ã‚‹\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMZmbC8TuqrH",
        "outputId": "6bbdd962-15ce-4bb9-bcc2-59ae2147af23"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ä»Šæ—¥ã¯UTCã§2025-03-26ã§ã™ã€‚\n",
            "\n",
            "ç¾åœ¨ã€20æ™‚24åˆ†30ç§’ã§ã™ã€‚\n",
            "ç¾åœ¨ã€11æ™‚24åˆ†31ç§’ã§ã™ã€‚\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Message History"
      ],
      "metadata": {
        "id": "4zZhAa9MzX8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic_ai import Agent\n",
        "from pydantic_ai.models.gemini import GeminiModel\n",
        "from pydantic_ai.messages import (\n",
        "    ModelRequest,\n",
        "    ModelResponse,\n",
        "    UserPromptPart,\n",
        "    SystemPromptPart,\n",
        "    TextPart\n",
        ")\n",
        "\n",
        "model = GeminiModel(\"gemini-2.0-flash\")\n",
        "\n",
        "# === é€£ç¶šçš„ãªä¼šè©±ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ ===\n",
        "\n",
        "agent = Agent(model=model, system_prompt=\"ã‚ãªãŸã¯æ•°å­¦è€…ã§ã™ã€‚\")\n",
        "result = await agent.run(\"1+1=?\")\n",
        "messages = result.all_messages()\n",
        "result = await agent.run(\"ãã‚Œã«2ã‚’æ›ã‘ã‚‹ã¨ï¼Ÿ\", message_history=messages,)\n",
        "print(result.data)\n",
        "\n",
        "# Langchainã®ã‚ˆã†ã«é€”ä¸­ã®ä¼šè©±ã‚’æ”¹ã–ã‚“ã™ã‚‹ã“ã¨ã‚‚å¯èƒ½ è©³ç´°ã¯ https://ai.pydantic.dev/api/messages/\n",
        "forged_messages = [\n",
        "    ModelRequest(parts=[SystemPromptPart(content=\"ã‚ãªãŸã¯ã—ã‚Šã¨ã‚Šã®ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚\"), UserPromptPart(content=\"ã—ã‚Šã¨ã‚Š\")]),\n",
        "    ModelResponse(parts=[TextPart(content=\"ã‚Šã‚“ã‚Š\"),]),\n",
        "    ModelRequest(parts=[UserPromptPart(content=\"ã‚Šã‹\")]),\n",
        "    ModelResponse(parts=[TextPart(content=\"ã‹ã‚Šã‚“\"),]),\n",
        "]\n",
        "result = await agent.run(\"ã€Œã‹ã‚Šã‚“ã€ã¯ã€Œã‚“ã€ã§çµ‚ã‚ã‚Šã¾ã™ã€‚ã‚ãªãŸã®è² ã‘ã§ã™\", message_history=forged_messages)\n",
        "print(result.data)"
      ],
      "metadata": {
        "id": "j2p0e24sA0Md",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b54bee0f-aeae-4e59-d2d2-61004a0c8f69"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2ã«2ã‚’æ›ã‘ã‚‹ã¨4ã«ãªã‚Šã¾ã™ã€‚\n",
            "\n",
            "å¤§å¤‰å¤±ç¤¼ã„ãŸã—ã¾ã—ãŸã€‚ã€Œã‹ã‚Šã‚“ã€ã§çµ‚ã‚ã£ã¦ã—ã¾ã„ã¾ã—ãŸã­ã€‚ç§ã®è² ã‘ã§ã™ã€‚\n",
            "\n",
            "æ”¹ã‚ã¦ã€ã—ã‚Šã¨ã‚Šã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚\n",
            "ä½•ã‹è¨€è‘‰ã‚’é ‚ã‘ã¾ã™ã§ã—ã‚‡ã†ã‹ï¼Ÿ\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multi-Agent-Systems"
      ],
      "metadata": {
        "id": "W-eB7pKuza0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from typing import Annotated, Optional\n",
        "from pydantic_ai import Agent, RunContext\n",
        "from pydantic_ai.models.gemini import GeminiModel\n",
        "from pydantic import BaseModel, StringConstraints\n",
        "from dataclasses import dataclass\n",
        "\n",
        "model = GeminiModel(\"gemini-2.0-flash\")\n",
        "\n",
        "# å‘¼ã³å‡ºã™AgentãŒå›ºå®šçš„ã§ã‚ã‚‹å ´åˆã€ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ã¯ä¸è¦\n",
        "\n",
        "@dataclass\n",
        "class JankenResult:\n",
        "    result: Annotated[str, StringConstraints(pattern=\"^(ã‚°ãƒ¼|ãƒãƒ§ã‚­|ãƒ‘ãƒ¼)$\")] | None\n",
        "\n",
        "@dataclass\n",
        "class JankenResults:\n",
        "    mario: JankenResult\n",
        "    luigi: JankenResult\n",
        "\n",
        "mario = Agent(\n",
        "    model=model, name=\"Mario\",\n",
        "    system_prompt=\"ã‚ãªãŸã¯ã‚¸ãƒ£ãƒ³ã‚±ãƒ³ã‚’ã™ã‚‹AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚\"\n",
        "                  \"'get_janken' toolã‚’ä½¿ç”¨ã—ã€ã‚¸ãƒ£ãƒ³ã‚±ãƒ³ã§ã€Œã‚°ãƒ¼ã€ã€ã€Œãƒãƒ§ã‚­ã€ã€ã€Œãƒ‘ãƒ¼ã€ã®ã©ã‚Œã‹ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«å‡ºã—ã¾ã™ã€‚\",\n",
        "    deps_type=None, result_type=JankenResult\n",
        ")\n",
        "luigi = Agent(\n",
        "    model=model, name=\"Luigi\",\n",
        "    system_prompt=\"ã‚ãªãŸã¯ã‚¸ãƒ£ãƒ³ã‚±ãƒ³ã‚’ã™ã‚‹AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚\"\n",
        "                  \"'get_janken' toolã‚’ä½¿ç”¨ã—ã€ã‚¸ãƒ£ãƒ³ã‚±ãƒ³ã§ã€Œã‚°ãƒ¼ã€ã€ã€Œãƒãƒ§ã‚­ã€ã€ã€Œãƒ‘ãƒ¼ã€ã®ã©ã‚Œã‹ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«å‡ºã—ã¾ã™ã€‚\",\n",
        "    deps_type=None, result_type=JankenResult\n",
        ")\n",
        "peach = Agent(\n",
        "    model=model, name=\"Peach\",\n",
        "    system_prompt=\"ã‚ãªãŸã¯ã‚¸ãƒ£ãƒ³ã‚±ãƒ³å‹è² ã®çµæœã‚’å‡ºåŠ›ã™ã‚‹AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚\"\n",
        "                  \"'prompt_janken' toolã‚’ä½¿ç”¨ã—ã€ã‚¸ãƒ£ãƒ³ã‚±ãƒ³å‹è² ã®çµæœã¨å‹æ•—ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚\",\n",
        "    deps_type=JankenResults, result_type=str\n",
        ")\n",
        "\n",
        "yoshi = Agent(\n",
        "    model=model, name=\"Yoshi\",\n",
        "    system_prompt=\"ã‚ãªãŸã¯è¦ªåˆ‡ãªAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ã™ã€‚\"\n",
        "                  \"get_janken_results' toolã‚’ä½¿ç”¨ã—çµæœã‚’æ•™ãˆã¦ãã ã•ã„ã€‚\",\n",
        "    deps_type=None, result_type=str\n",
        ")\n",
        "\n",
        "@mario.tool\n",
        "def get_janken(ctx: RunContext[None]) -> str:\n",
        "    return random.choice([\"ã‚°ãƒ¼\", \"ãƒãƒ§ã‚­\", \"ãƒ‘ãƒ¼\"])\n",
        "\n",
        "@luigi.tool\n",
        "def get_janken(ctx: RunContext[None]) -> str:\n",
        "    return random.choice([\"ã‚°ãƒ¼\", \"ãƒãƒ§ã‚­\", \"ãƒ‘ãƒ¼\"])\n",
        "\n",
        "@peach.tool\n",
        "async def prompt_janken(ctx: RunContext[None]) -> str:\n",
        "    mario_response = await mario.run(\n",
        "        f'ã‚¸ãƒ£ãƒ³ã‚±ãƒ³ã€',\n",
        "        usage=ctx.usage,\n",
        "    )\n",
        "    luigi_response = await luigi.run(\n",
        "        f'ã‚¸ãƒ£ãƒ³ã‚±ãƒ³ã€',\n",
        "        usage=ctx.usage,\n",
        "    )\n",
        "    jankenResults = JankenResults(mario=mario_response.data, luigi=luigi_response.data)\n",
        "    print(jankenResults)\n",
        "    if jankenResults.mario.result == \"ã‚°ãƒ¼\" and jankenResults.luigi.result == \"ã‚°ãƒ¼\":\n",
        "        return \"åŒæ–¹ã‚°ãƒ¼ã§å¼•ãåˆ†ã‘ã§ã™ã€‚\"\n",
        "    elif jankenResults.mario.result == \"ã‚°ãƒ¼\" and jankenResults.luigi.result == \"ãƒãƒ§ã‚­\":\n",
        "        return \"MarioãŒã‚°ãƒ¼ã§å‹ã¡ã§ã™ã€‚\"\n",
        "    elif jankenResults.mario.result == \"ã‚°ãƒ¼\" and jankenResults.luigi.result == \"ãƒ‘ãƒ¼\":\n",
        "        return \"LuigiãŒãƒ‘ãƒ¼ã§å‹ã¡ã§ã™ã€‚\"\n",
        "    elif jankenResults.mario.result == \"ãƒãƒ§ã‚­\" and jankenResults.luigi.result == \"ã‚°ãƒ¼\":\n",
        "        return \"LuigiãŒã‚°ãƒ¼ã§å‹ã¡ã§ã™ã€‚\"\n",
        "    elif jankenResults.mario.result == \"ãƒãƒ§ã‚­\" and jankenResults.luigi.result == \"ãƒãƒ§ã‚­\":\n",
        "        return \"åŒæ–¹ãƒãƒ§ã‚­ã§å¼•ãåˆ†ã‘ã§ã™ã€‚\"\n",
        "    elif jankenResults.mario.result == \"ãƒãƒ§ã‚­\" and jankenResults.luigi.result == \"ãƒ‘ãƒ¼\":\n",
        "        return \"MarioãŒãƒãƒ§ã‚­ã§å‹ã¡ã§ã™ã€‚\"\n",
        "    elif jankenResults.mario.result == \"ãƒ‘ãƒ¼\" and jankenResults.luigi.result == \"ã‚°ãƒ¼\":\n",
        "        return \"MarioãŒãƒ‘ãƒ¼ã§å‹ã¡ã§ã™ã€‚\"\n",
        "    elif jankenResults.mario.result == \"ãƒ‘ãƒ¼\" and jankenResults.luigi.result == \"ãƒãƒ§ã‚­\":\n",
        "        return \"LuigiãŒãƒãƒ§ã‚­ã§å‹ã¡ã§ã™ã€‚\"\n",
        "    elif jankenResults.mario.result == \"ãƒ‘ãƒ¼\" and jankenResults.luigi.result == \"ãƒ‘ãƒ¼\":\n",
        "        return \"åŒæ–¹ãƒ‘ãƒ¼ã§å¼•ãåˆ†ã‘ã§ã™ã€‚\"\n",
        "    else:\n",
        "        return \"ä¸æ˜ãªçµæœã§ã™ã€‚\"\n",
        "\n",
        "@yoshi.tool\n",
        "async def get_janken_results(ctx: RunContext[None]) -> str:\n",
        "    response = await peach.run(\"ã‚¸ãƒ£ãƒ³ã‚±ãƒ³å‹è² ã®çµæœã¨å‹æ•—ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„\", usage=ctx.usage)\n",
        "    return response.data\n",
        "\n",
        "result = await yoshi.run(\"ã©ã¡ã‚‰ãŒã©ã®æ‰‹ã‚’å‡ºã—ãŸã‹ã¨ã€å‹æ•—ã‚’æ•™ãˆã¦ä¸‹ã•ã„ã€‚\", deps=None, result_type=str)\n",
        "print(result.data)"
      ],
      "metadata": {
        "id": "fy3vrm8q9k66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6400599-bd78-40fe-845c-b2d1a25c7585"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JankenResults(mario=JankenResult(result='ã‚°ãƒ¼'), luigi=JankenResult(result='ã‚°ãƒ¼'))\n",
            "åŒæ–¹ã‚°ãƒ¼ã§å¼•ãåˆ†ã‘ã§ã™ã€‚\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image and Audio\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "K2GAdGMi5tCy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ç”»åƒèªè­˜\n",
        "import httpx\n",
        "from pydantic_ai import Agent, BinaryContent\n",
        "from pydantic_ai.models.gemini import GeminiModel\n",
        "\n",
        "image_response = httpx.get('http://www.sakado-jigenji.jp/images/k_logo.png')\n",
        "model = GeminiModel(\"gemini-2.0-flash\")\n",
        "agent = Agent(model=model)\n",
        "result = await agent.run(\n",
        "    [\n",
        "        'ã“ã‚Œã¯ä½•ï¼Ÿ',\n",
        "        BinaryContent(data=image_response.content, media_type='image/png'),  # ã ã„ãŸã„ã®ç”»åƒã«å¯¾å¿œã—ã¦ã„ã‚‹\n",
        "    ]\n",
        ")\n",
        "print(result.data)\n",
        "\n",
        "# éŸ³å£°èªè­˜\n",
        "\n",
        "import httpx\n",
        "from pydantic_ai import Agent, BinaryContent\n",
        "from pydantic_ai.models.gemini import GeminiModel\n",
        "\n",
        "audio_response = httpx.get('http://www.sakado-jigenji.jp/dl/pannyashingyou16.mp3')\n",
        "model = GeminiModel(\"gemini-2.0-flash\")\n",
        "agent = Agent(model=model)\n",
        "result = await agent.run(\n",
        "    [\n",
        "        'æ–‡å­—èµ·ã“ã—ã—ã¦ãã ã•ã„',\n",
        "        BinaryContent(data=audio_response.content, media_type='audio/mpeg'), # mp3, wavã«å¯¾å¿œã—ã¦ã„ã‚‹ã¿ãŸã„ã€‚\n",
        "    ]\n",
        ")\n",
        "print(result.data)\n"
      ],
      "metadata": {
        "id": "2YO9PsLokdk2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd74c297-440a-4888-ad9c-fa9cb20ce45b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ã“ã‚Œã¯ã€çœŸè¨€å®—æ™ºå±±æ´¾ã®æ…ˆçœ¼å¯ºï¼ˆã‚¸ã‚²ãƒ³ã‚¸ï¼‰ã¨ã„ã†ãŠå¯ºã®çœ‹æ¿ã§ã™ã€‚\n",
            "ç„¡ç€¬æ·±è¿¦èˆ¬è‹¥æ³¢ç¾…èœœå¤šçµŒã€‚\n",
            "è¦³è‡ªåœ¨è©è–©è¡Œæ·±èˆ¬è‹¥æ³¢ç¾…èœœå¤šæ™‚ç…§è¦‹äº”è˜Šçš†ç©ºåº¦ä¸€åˆ‡è‹¦å„èˆåˆ©å­ã€è‰²ä¸ç•°ç©ºã€ç©ºä¸ç•°è‰²ã€è‰²å³æ˜¯ç©ºã€ç©ºå³æ˜¯è‰²ã€å—æƒ³è¡Œè­˜äº¦å¾©å¦‚æ˜¯èˆåˆ©å­æ˜¯è«¸æ³•ç©ºç›¸ä¸ç”Ÿä¸æ»…ä¸å¢ä¸æµ„ä¸å¢—ä¸æ¸›æ˜¯æ•…ç©ºä¸­ç„¡è‰²ç„¡å—æƒ³è¡Œè­˜ç„¡çœ¼è€³é¼»èˆŒèº«æ„ç„¡è‰²å£°é¦™å‘³è§¦æ³•ç„¡çœ¼ç•Œä¹ƒè‡³ç„¡æ„è­˜ç•Œç„¡ç„¡æ˜äº¦ç„¡ç„¡æ˜ç›¡ä¹ƒè‡³ç„¡è€æ­»äº¦ç„¡è€æ­»ç›¡ç„¡è‹¦é›†æ»…é“ç„¡æ™ºäº¦ç„¡å¾—ä»¥ç„¡æ‰€å¾—æ•…ã€‚\n",
            "è©æè–©åŸµä¾èˆ¬è‹¥æ³¢ç¾…èœœå¤šæ•…å¿ƒç„¡åœ­ç¤™ç„¡åœ­ç¤™æ•…ç„¡æœ‰ææ€–é é›¢ä¸€åˆ‡é¡›å€’å¤¢æƒ³ç©¶ç«Ÿæ¶…æ§ƒä¸‰ä¸–è«¸ä»ä¾èˆ¬è‹¥æ³¢ç¾…èœœå¤šæ•…å¾—é˜¿è€¨å¤šç¾…ä¸‰è—ä¸‰è©ææ•…çŸ¥èˆ¬è‹¥æ³¢ç¾…èœœå¤šæ˜¯å¤§ç¥å‘ªæ˜¯å¤§æ˜å‘ªæ˜¯ç„¡ä¸Šå‘ªæ˜¯ç„¡ç­‰ç­‰å‘ªèƒ½é™¤ä¸€åˆ‡è‹¦çœŸå®Ÿä¸è™šæ•…èª¬èˆ¬è‹¥æ³¢ç¾…èœœå¤šå‘ªå³èª¬å‘ªæ›°ç¾¯è«¦ç¾¯è«¦æ³¢ç¾…ç¾¯è«¦æ³¢ç¾…åƒ§ç¾¯è«¦è©æè–©å©†è¨¶èˆ¬è‹¥å¿ƒçµŒã€‚\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "clIxyze2cHFj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}